{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation, InputLayer, LeakyReLU, Reshape, Flatten\n",
    "from keras.layers.pooling import MaxPooling1D, MaxPooling2D, AveragePooling1D, AveragePooling2D\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_index(fold_id, key='train', n=None):\n",
    "    \n",
    "    with open(os.path.join(DESTDIR, 'experiment_{:02d}.json'.format(fold_id)), 'r') as fdesc:\n",
    "        index = json.load(fdesc)[key]\n",
    "    \n",
    "    perm = np.random.permutation(len(index))\n",
    "    if n is not None:\n",
    "        perm = perm[:n]\n",
    "        \n",
    "    index = [index[_] for _ in perm]\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(X):\n",
    "    return librosa.logamplitude(X**2, ref_power=np.max, top_db=80)\n",
    "\n",
    "\n",
    "def load_data(index, n_harm=1):\n",
    "    \n",
    "    X, Y = [], []\n",
    "    for item in index:\n",
    "        with np.load(os.path.join(DESTDIR, 'features', '{}.npz'.format(item['filename']))) as data:\n",
    "            if n_harm is None:\n",
    "                n_harm = data['C'].shape[0]\n",
    "            X.append(preprocess(data['C'][:n_harm]))\n",
    "            Y.append(item['classID'])\n",
    "    \n",
    "    X = np.asarray(X).swapaxes(3, 1)\n",
    "    Y = np.asarray(Y)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DESTDIR = '/home/bmcfee/working/minst/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FOLD_ID = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = load_index(FOLD_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_index = load_index(FOLD_ID, key='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_HARM = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, Y = load_data(index, n_harm=N_HARM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xt, Yt = load_data(test_index, n_harm=N_HARM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=X.shape[1:], name='input'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(8, 5, (4 - X.shape[3] + 1) * 9, bias=False))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "\n",
    "model.add(Conv2D(16, 5, 5,  bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "\n",
    "#model.add(Conv2D(64, 3, model.output_shape[2], bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "\n",
    "#model.add(AveragePooling2D(pool_size=(model.output_shape[1], 1)))\n",
    "model.add(MaxPooling2D(pool_size=(model.output_shape[1], 1)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_fn = '/home/bmcfee/working/minst/models_{}.hdf5'.format(N_HARM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26610 samples, validate on 8870 samples\n",
      "Epoch 1/30\n",
      "26610/26610 [==============================] - 28s - loss: 0.4452 - acc: 0.8549 - val_loss: 0.3164 - val_acc: 0.8843\n",
      "Epoch 2/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.1268 - acc: 0.9611 - val_loss: 0.1351 - val_acc: 0.9554\n",
      "Epoch 3/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0778 - acc: 0.9752 - val_loss: 0.0745 - val_acc: 0.9744\n",
      "Epoch 4/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0596 - acc: 0.9813 - val_loss: 0.0683 - val_acc: 0.9772\n",
      "Epoch 5/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0448 - acc: 0.9855 - val_loss: 0.0914 - val_acc: 0.9703\n",
      "Epoch 6/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0381 - acc: 0.9881 - val_loss: 0.0675 - val_acc: 0.9770\n",
      "Epoch 7/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0349 - acc: 0.9882 - val_loss: 0.0917 - val_acc: 0.9688\n",
      "Epoch 8/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0279 - acc: 0.9910 - val_loss: 0.0888 - val_acc: 0.9705\n",
      "Epoch 9/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0260 - acc: 0.9916 - val_loss: 0.0566 - val_acc: 0.9816\n",
      "Epoch 10/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0247 - acc: 0.9923 - val_loss: 0.0714 - val_acc: 0.9764\n",
      "Epoch 11/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0215 - acc: 0.9927 - val_loss: 0.0579 - val_acc: 0.9816\n",
      "Epoch 12/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0184 - acc: 0.9935 - val_loss: 0.0623 - val_acc: 0.9821\n",
      "Epoch 13/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0190 - acc: 0.9939 - val_loss: 0.0599 - val_acc: 0.9808\n",
      "Epoch 14/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0190 - acc: 0.9938 - val_loss: 0.0348 - val_acc: 0.9905\n",
      "Epoch 15/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0123 - acc: 0.9964 - val_loss: 0.0686 - val_acc: 0.9811\n",
      "Epoch 16/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0142 - acc: 0.9953 - val_loss: 0.0431 - val_acc: 0.9858\n",
      "Epoch 17/30\n",
      "26610/26610 [==============================] - 28s - loss: 0.0149 - acc: 0.9946 - val_loss: 0.0650 - val_acc: 0.9832\n",
      "Epoch 18/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0097 - acc: 0.9970 - val_loss: 0.0775 - val_acc: 0.9796\n",
      "Epoch 19/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0182 - acc: 0.9936 - val_loss: 0.0531 - val_acc: 0.9851\n",
      "Epoch 20/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0088 - acc: 0.9971 - val_loss: 0.0404 - val_acc: 0.9878\n",
      "Epoch 21/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0062 - acc: 0.9980 - val_loss: 0.0451 - val_acc: 0.9875\n",
      "Epoch 22/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0154 - acc: 0.9947 - val_loss: 0.0966 - val_acc: 0.9756\n",
      "Epoch 23/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0087 - acc: 0.9971 - val_loss: 0.0379 - val_acc: 0.9896\n",
      "Epoch 24/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0097 - acc: 0.9971 - val_loss: 0.1382 - val_acc: 0.9682\n",
      "Epoch 25/30\n",
      "26610/26610 [==============================] - 27s - loss: 0.0115 - acc: 0.9963 - val_loss: 0.0416 - val_acc: 0.9884\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, to_categorical(Y, nb_classes=12),\n",
    "                    callbacks=[EarlyStopping('val_loss', patience=10),\n",
    "                               ModelCheckpoint(weight_fn, save_best_only=True)],\n",
    "                    validation_split=0.25, batch_size=32, shuffle=True,\n",
    "                    nb_epoch=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(weight_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3417/3417 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.2804923124539425, 0.59555165323556636]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(N_HARM)\n",
    "model.evaluate(Xt, to_categorical(Yt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3417/3417 [==============================] - 1s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6730064784779266, 0.64062042701373434]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(N_HARM)\n",
    "model.evaluate(Xt, to_categorical(Yt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3417/3417 [==============================] - 1s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.2844954945031475, 0.61018437223892164]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(N_HARM)\n",
    "model.evaluate(Xt, to_categorical(Yt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3417/3417 [==============================] - 2s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6120286197176723, 0.60608721092530848]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(N_HARM)\n",
    "model.evaluate(Xt, to_categorical(Yt))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
